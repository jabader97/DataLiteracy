{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Literacy\n",
    "#### University of Tübingen, Winter Term 2020/21\n",
    "## Exercise Sheet 6\n",
    "&copy; 2020 Prof. Dr. Philipp Hennig & Lukas Tatzel\n",
    "\n",
    "This sheet is **due on Tuesday 15 December 2020 at 12noon sharp (i.e. before the start of the lecture).**\n",
    "\n",
    "---\n",
    "\n",
    "## Hypothesis Testing & *Hunting* for Significance \n",
    "\n",
    "**What is this week's tutorial about?** In this week's tutorial, we will analyse data from the 1. Fußball-Bundesliga (the German premier soccer league), reproducing and extending the analysis done in the lecture. The goal is to find out if there are teams that achieve significantly worse results this year than in previous years (possibly caused by empty stadiums etc. due to the Corona-pandemic). For that purpose we will conduct a hypothesis test. To be more precise, we will perform multiple tests, i.e. we will compute multiple $p$-values. We will also discuss whether and how we should therefore adapt our testing strategy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T09:18:44.327461Z",
     "iopub.status.busy": "2020-12-03T09:18:44.327152Z",
     "iopub.status.idle": "2020-12-03T09:18:44.730626Z",
     "shell.execute_reply": "2020-12-03T09:18:44.729897Z",
     "shell.execute_reply.started": "2020-12-03T09:18:44.327397Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make inline plots vector graphics\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from IPython.display import set_matplotlib_formats\n",
    "\n",
    "# Plotting setup\n",
    "set_matplotlib_formats(\"pdf\", \"svg\")\n",
    "plt.rcParams[\"text.usetex\"] = True\n",
    "plt.rcParams[\"text.latex.preamble\"] = r\"\\usepackage{amsfonts} \\usepackage{amsmath}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will use data provided by OpenLigaDB (https://www.openligadb.de/). The function `get_league_table` allows you to retrieve the data via the API interface and convert it into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T09:18:45.089914Z",
     "iopub.status.busy": "2020-12-03T09:18:45.089660Z",
     "iopub.status.idle": "2020-12-03T09:18:45.300391Z",
     "shell.execute_reply": "2020-12-03T09:18:45.299727Z",
     "shell.execute_reply.started": "2020-12-03T09:18:45.089890Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TeamInfoId</th>\n",
       "      <th>TeamName</th>\n",
       "      <th>ShortName</th>\n",
       "      <th>TeamIconUrl</th>\n",
       "      <th>Points</th>\n",
       "      <th>OpponentGoals</th>\n",
       "      <th>Goals</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Won</th>\n",
       "      <th>Lost</th>\n",
       "      <th>Draw</th>\n",
       "      <th>GoalDiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>FC Bayern München</td>\n",
       "      <td>Bayern</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1635</td>\n",
       "      <td>RB Leipzig</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/en/thum...</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Bayer Leverkusen</td>\n",
       "      <td>Leverkusen</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/de/thum...</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>BV Borussia Dortmund 09</td>\n",
       "      <td>Dortmund</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131</td>\n",
       "      <td>VfL Wolfsburg</td>\n",
       "      <td>Wolfsburg</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TeamInfoId                 TeamName   ShortName  \\\n",
       "0          40        FC Bayern München      Bayern   \n",
       "1        1635               RB Leipzig     Leipzig   \n",
       "2           6         Bayer Leverkusen  Leverkusen   \n",
       "3           7  BV Borussia Dortmund 09    Dortmund   \n",
       "4         131            VfL Wolfsburg   Wolfsburg   \n",
       "\n",
       "                                         TeamIconUrl  Points  OpponentGoals  \\\n",
       "0  https://upload.wikimedia.org/wikipedia/commons...      22             13   \n",
       "1  https://upload.wikimedia.org/wikipedia/en/thum...      20              6   \n",
       "2  https://upload.wikimedia.org/wikipedia/de/thum...      19              9   \n",
       "3  https://upload.wikimedia.org/wikipedia/commons...      18              9   \n",
       "4  https://upload.wikimedia.org/wikipedia/commons...      17              8   \n",
       "\n",
       "   Goals  Matches  Won  Lost  Draw  GoalDiff  \n",
       "0     31        9    7     1     1        18  \n",
       "1     18        9    6     1     2        12  \n",
       "2     16        9    5     0     4         7  \n",
       "3     21        9    6     3     0        12  \n",
       "4     14        9    4     0     5         6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "API_ENDPOINT = \"https://www.openligadb.de/api\"\n",
    "\n",
    "def get_league_table(league, year):\n",
    "    \"\"\"\n",
    "    Get team rankings as Pandas dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    league : str\n",
    "        'bl1' for 1. Bundesliga, see https://github.com/OpenLigaDB/OpenLigaDB-Samples\n",
    "    year : int\n",
    "        Get data for this year\n",
    "    \"\"\"\n",
    "    response = requests.get(f\"{API_ENDPOINT}/getbltable/{league}/{year}\")\n",
    "    teams = response.json()\n",
    "    return pd.DataFrame(teams)\n",
    "\n",
    "# Get data for the 1. Bundesliga ('bl1') for 2020\n",
    "data = get_league_table(league=\"bl1\", year=2020)\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Your first task is to essentially recreate the following table from lecture 6. \n",
    "\n",
    "<img src=\"Table.PNG\" alt=\"Drawing\" style=\"width: 750px;\"/>\n",
    "\n",
    "**Recommended Steps:**\n",
    "1. First, gather data for all years from 2010 to 2020 and store this data into a single Pandas dataframe. Each time you receive a dataframe from `get_league_table`, extract the relevant columns and add the corresponding year as a new column `\"year\"`.\n",
    "2. Split this dataframe into two separate dataframes: One for the year 2020, the other one for everything before (i.e. 2010 to 2019). \n",
    "3. Merge the two dataframes from on the `\"TeamName\"`-column. Make sure that you only include teams that play in 2020 and played in at least one other season in the past. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T09:18:45.709439Z",
     "iopub.status.busy": "2020-12-03T09:18:45.709154Z",
     "iopub.status.idle": "2020-12-03T09:18:46.947078Z",
     "shell.execute_reply": "2020-12-03T09:18:46.946267Z",
     "shell.execute_reply.started": "2020-12-03T09:18:45.709410Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Gather data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Split dataframe\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Merge dataframes\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to find out if there are teams that achieve significantly worse results this year than in previous years. In the lecture, you already learned about a statistical test for this purpose: \n",
    "\n",
    "- First, we put a beta-prior on $f_0$ (the winning probability before 2020) which is based on $m_0$ (the number of wins before 2020) in $n_0$ matches (the number of matches before 2020).\n",
    "\n",
    "- Under the null hypothesis $H_0: f_1 = f_0$, the number of wins in 2020 $m_1$ (given the number of matches in 2020 $n_1$) follows a binomial distribution. \n",
    "\n",
    "- Putting these building blocks together, we obtain a [beta-binomial distribution](https://en.wikipedia.org/wiki/Beta-binomial_distribution) for the *evidence* $p(m_1 \\vert n_1, m_0, n_0)$. This tells us the probability to oberserve $m_1$ wins in 2020, given the number of matches in 2020 $n_1$ and the statistics $m_0$, $n_0$ for the years before. \n",
    "\n",
    "- The $p$-value represents the probability to observe a certain number of wins or *more extreme* results. Lets assume, the team we consider, has won $3$ times this season so far. Since we are interested in teams that have played particularly badly this year, we sum $p(m_1 \\vert n_1, m_0, n_0)$ over $m_1 = 0, 1, 2, 3$. Evaluating the cumulative distribution function `betabinom.cdf` performs this summation for us. \n",
    "\n",
    "- If this probability is small, then it is very unlikely that the oberved data has been generated from the winning probability $f_0$. Or, in other woirds, the team has played particularly badly so far. We thus reject $H_0$ if $p \\leq \\alpha := 5 \\%$. \n",
    "\n",
    "**Task:** Compute the $p$-values for every team and add the results as a new column `\"p-value (won)\"`. Check if there are teams whose $p$-value falls below the $5 \\%$ threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T09:18:46.979525Z",
     "iopub.status.busy": "2020-12-03T09:18:46.979289Z",
     "iopub.status.idle": "2020-12-03T09:18:47.562397Z",
     "shell.execute_reply": "2020-12-03T09:18:47.561685Z",
     "shell.execute_reply.started": "2020-12-03T09:18:46.979502Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import betabinom\n",
    "\n",
    "def p_val_won(m_1, n_1, m_0, n_0):\n",
    "    \"\"\"\n",
    "    Compute p-value by summing the evidence p(m_1 | n_1, m_0, n_0) over the \n",
    "    observed number of wins and 'more extreme' (i.e. smaller) results.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    m_1 : int\n",
    "        Number of wins in 2020 (0 <= m_1 <= n_1)\n",
    "    n_1 : int\n",
    "        Number of matches in 2020 (n_1 > 0)\n",
    "    m_0 : int\n",
    "        Number of wins before 2020 (0 <= m_0 <= n_0)\n",
    "    n_0 : int\n",
    "        Number of matches before 2020 (n_0 > 0)\n",
    "    \"\"\"\n",
    "    return betabinom.cdf(m_1, n_1, m_0 + 1, n_0 - m_0 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T09:18:47.564144Z",
     "iopub.status.busy": "2020-12-03T09:18:47.563868Z",
     "iopub.status.idle": "2020-12-03T09:18:47.595089Z",
     "shell.execute_reply": "2020-12-03T09:18:47.594130Z",
     "shell.execute_reply.started": "2020-12-03T09:18:47.564116Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute p-values, filter for significant results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to find teams that play significantly worse this year compared to previous years. We did this by checking whether the number of games won this year is surprisingly low. Now, we will use an alternative approach: We check whether the number of games *lost* this year is particularly *high*. For this, we can re-use the statistical beta-binomial model from above by simply plugging in the number of *lost* games for $m_0$ and $m_1$. \n",
    "\n",
    "**Task:** Compute the corresponding $p$-values and store the results in a new column `\"p-value (lost)`. Note that you cannot simply use the `p_val_won` fuction from above. This time, the question is: What is the probability for oberving $m_1$ or *more* lost matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T09:18:47.659651Z",
     "iopub.status.busy": "2020-12-03T09:18:47.659397Z",
     "iopub.status.idle": "2020-12-03T09:18:47.691939Z",
     "shell.execute_reply": "2020-12-03T09:18:47.691178Z",
     "shell.execute_reply.started": "2020-12-03T09:18:47.659628Z"
    }
   },
   "outputs": [],
   "source": [
    "def p_val_lost(m_1, n_1, m_0, n_0):\n",
    "    \"\"\"\n",
    "    Compute p-value by ...\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    m_1 : int\n",
    "        Number of lost matches in 2020 (0 <= m_1 <= n_1)\n",
    "    n_1 : int\n",
    "        Number of matches in 2020 (n_1 > 0)\n",
    "    m_0 : int\n",
    "        Number of lost matches before 2020 (0 <= m_0 <= n_0)\n",
    "    n_0 : int\n",
    "        Number of matches before 2020 (n_0 > 0)\n",
    "    \"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute p-values, filter for significant results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now, we conducted $2 \\cdot 17 = 34$ hypothesis tests at significance level $\\alpha = 5 \\%$. $\\alpha$ corresponds to the probability of a type I error, i.e. rejecting the null hypothesis given that it is true. However, the more tests we perform, the higher the chance of observing a rare event simply due to chance. For example, if we assume that $H_0$ holds for every team, the chance of falsely rejecting at least one out of $34$ hypothesis is $1 - (1-0.05)^{34} \\approx 83 \\%$. Thus, it is quite likely that one of the results we found is a type I error. The Bonferroni correction is one possibility for compensating for that effect by decreasing the significance level. The significance level is defined as the original one divided by the total number of hypothesis. \n",
    "\n",
    "**Task:** Define the new significance level and see whether you can (still) find significant results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T09:18:48.365359Z",
     "iopub.status.busy": "2020-12-03T09:18:48.365108Z",
     "iopub.status.idle": "2020-12-03T09:18:48.371750Z",
     "shell.execute_reply": "2020-12-03T09:18:48.371072Z",
     "shell.execute_reply.started": "2020-12-03T09:18:48.365336Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter for significant results (Bonferroni correction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bonferroni method tends to be too *conservative*, i.e. the significance level might be too restrictive. This is especially the case when the tests are dependent. \n",
    "\n",
    "**Task:** Think about if the tests we performed are dependent or independent and give a short explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conducted multiple hypothesis tests at significance level $\\alpha = 5 \\%$. $\\alpha$ corresponds to the probability of a type I error, i.e. $\\alpha = P(\\text{type 1 error}) = P(p \\leq \\alpha\\,|\\,H_0\\,\\text{ is true}) = \\text{cdf}_p(\\alpha)$. So, under $H_0$, the cumulative distribution function of the $p$-value at $\\alpha$ is $\\text{cdf}_p(\\alpha) = \\alpha$. That implies that $p$ is uniformly distributed under $H_0$. Let us visually explore, if the observed $p$-values are likely to be drawn from a uniform distribution. This can be done by a so-called Q-Q plot. \n",
    "\n",
    "The idea of a Q-Q Plot is to compare the empirical quantiles of the empirical distribution of the $p$-values with the quantiles of the theoretical distribution (the uniform distribution as explained above). Let $\\beta \\in (0, 1)$. \n",
    "- The theoretical $\\beta$-quantile of the uniform distribution is $q_{\\beta} = \\beta$.\n",
    "- The empirical $\\beta$-quantile of the *ascendingly ordered* sample $(p_1, ..., p_n)$ is $q_{\\beta} = p_{\\lfloor n\\cdot\\beta + 1\\rfloor}$\n",
    "\n",
    "**Task:** Complement the two functions below such that they return the quantiles defined above. Do not use `numpy.quantile` or similar.  Generate a vector that discretizes the variable $\\beta$ and compute the corresponding quantiles. Plot the theoretical quantiles over the empirical quantiles. If the distributions are *similar*, the points will lie on the $45°$ line $y = x$. The result should look like this: \n",
    "\n",
    "<img src=\"Plot.PNG\" alt=\"Drawing\" style=\"width: 350px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T09:18:49.818145Z",
     "iopub.status.busy": "2020-12-03T09:18:49.817894Z",
     "iopub.status.idle": "2020-12-03T09:18:49.823192Z",
     "shell.execute_reply": "2020-12-03T09:18:49.822093Z",
     "shell.execute_reply.started": "2020-12-03T09:18:49.818121Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "def q_theoretical(beta):\n",
    "    \"\"\"\n",
    "    Compute theoretical beta-quantile of uniform distribution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    beta : array-like, shape=(n,)\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "def q_empirical(beta, p):\n",
    "    \"\"\"\n",
    "    Compute empirical beta-quantile of sample p.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    beta : array-like, shape=(n,)\n",
    "    p : array-like, shape=(n,)\n",
    "        Unordered sample\n",
    "    \"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T09:18:50.506118Z",
     "iopub.status.busy": "2020-12-03T09:18:50.505864Z",
     "iopub.status.idle": "2020-12-03T09:19:01.843109Z",
     "shell.execute_reply": "2020-12-03T09:19:01.842432Z",
     "shell.execute_reply.started": "2020-12-03T09:18:50.506095Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Q-Q Plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the two generated lines do not coincide perfectly with the $45°$ line $y = x$. That raises the question, what deviation from that line we would expect if the $p$-values were actually drawn from a uniform distribution. One way to approach this question visually is to generate multiple samples of a uniform distribution (each sample consisting of $17$ numbers, like `p-values (won)` and `p-values (lost)`) and make a Q-Q Plot for each sample. So, we basically sample Q-Q plots under $H_0$. \n",
    "\n",
    "**Task:** Generate multiple (e.g. $100$) samples as desribed above and show the corresponding Q-Q Plots together with the two lines from the previous task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T09:25:47.023729Z",
     "iopub.status.busy": "2020-12-03T09:25:47.023411Z",
     "iopub.status.idle": "2020-12-03T09:25:47.468593Z",
     "shell.execute_reply": "2020-12-03T09:25:47.467972Z",
     "shell.execute_reply.started": "2020-12-03T09:25:47.023696Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Q-Q Plot\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
