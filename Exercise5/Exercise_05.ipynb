{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Literacy\n",
    "#### University of Tübingen, Winter Term 2020/21\n",
    "## Exercise Sheet 5\n",
    "&copy; 2020 Prof. Dr. Philipp Hennig & Marius Hobbhahn\n",
    "\n",
    "This sheet is **due on Tuesday 10 December 2020 at 12noon sharp (i.e. before the start of the lecture).**\n",
    "\n",
    "---\n",
    "\n",
    "This week's exercise sheet is inspired by a recently viral \"Who is talking in popular films\" post which you can find [here](https://public.tableau.com/views/WordDataWorking/WhoIsTalking?:language=en&:display_count=y&publish=yes&:origin=viz_share_link&:showVizHome=no)\n",
    "\n",
    "We want to investigate whether the average user rating of films on [IMDb](https://www.imdb.com) is related to how much of the dialogue is done by male vs female characters. This pop-culture data is a less serious variant of a [data analysis](https://zoonosen.charite.de/fileadmin/user_upload/microsites/m_cc05/virologie-ccm/dateien_upload/Weitere_Dateien/analysis-of-SARS-CoV-2-viral-load-by-patient-age.pdf) problem that was [hotly debated](https://www.bild.de/politik/inland/politik-inland/fragwuerdige-methoden-drosten-studie-ueber-ansteckende-kinder-grob-falsch-70862170.bild.html) in [Germany](https://www.t-online.de/nachrichten/panorama/id_87944112/kampagne-gegen-corona-experten-das-ist-dran-am-bild-artikel-gegen-drosten.html) earlier [this year](https://www.tagesspiegel.de/gesellschaft/medien/schwere-verstoesse-gegen-sorgfaltspflicht-presserat-ruegt-bild-fuer-artikel-ueber-drosten-studie/26179910.html) in the context of the pandemic (the connection will be made clearer in lectures 6 and 7).\n",
    "\n",
    "The goal of the exercise is to gain an intuition for how to inspect and analyse data without necessarily following a strict statistical recipe. In fact we will see that pre-packaged stats can be dangerous or silly if applied without context, and that sometimes a less formal but richer visual analysis can be more useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Who_is_talking_screenshot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T19:31:07.923900Z",
     "iopub.status.busy": "2020-11-28T19:31:07.923627Z",
     "iopub.status.idle": "2020-11-28T19:31:08.083170Z",
     "shell.execute_reply": "2020-11-28T19:31:08.082410Z",
     "shell.execute_reply.started": "2020-11-28T19:31:07.923844Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Make inline plots vector graphics\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "\n",
    "set_matplotlib_formats(\"pdf\", \"svg\")\n",
    "\n",
    "matplotlib.rc(\"font\", **{\"family\": \"serif\", \"serif\": [\"Computer Modern\"]})\n",
    "plt.rcParams[\"text.usetex\"] = True\n",
    "plt.rcParams[\"text.latex.preamble\"] = r\"\\usepackage{amsfonts} \\usepackage{amsmath}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Data preparation\n",
    "\n",
    "For this exercise we do the entire data wrangling for you such that you can exclusively focus on the statistical analysis. The data was extracted from the [original tableau datafile](https://public.tableau.com/views/WordDataWorking/WhoIsTalking?:language=en&:display_count=y&publish=yes&:origin=viz_share_link&:showVizHome=no) by us. Everything you need is given in `df_combined` which contains meta data about movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T19:31:11.518078Z",
     "iopub.status.busy": "2020-11-28T19:31:11.517631Z",
     "iopub.status.idle": "2020-11-28T19:31:12.065063Z",
     "shell.execute_reply": "2020-11-28T19:31:12.064313Z",
     "shell.execute_reply.started": "2020-11-28T19:31:11.518028Z"
    }
   },
   "outputs": [],
   "source": [
    "# import all .csv files\n",
    "df_combined = pd.read_csv(\"df_combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"length of df_combined: \", len(df_combined))\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Understanding the data\n",
    "\n",
    "We begin by visualizing the data in a scatter plot. We recreate the \"Who is talking in popular films\" scatter plot. \n",
    "\n",
    "The necessary components of that plot are percentFemaleDialoge on the x-axis, userRating on the y-axis and two different color schemes for majority male or majority female films. Everything else, such as showing some titles, adapting the size or the marginal plot above is optional. You are also not supposed to filter for films above 200k ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T19:32:40.339468Z",
     "iopub.status.busy": "2020-11-28T19:32:40.339212Z",
     "iopub.status.idle": "2020-11-28T19:32:40.344999Z",
     "shell.execute_reply": "2020-11-28T19:32:40.344409Z",
     "shell.execute_reply.started": "2020-11-28T19:32:40.339445Z"
    }
   },
   "outputs": [],
   "source": [
    "# recreating the \"Who is talking in popular films\" scatter plot\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Pre-packaged Statistics\n",
    "\n",
    "The tempting next step is to do some *tests*. For example, we may want to apply binary tests for contingency tables, as introduced in lecture 04, to test whether there is a bias against films with majority female dialogue. Doing so is actually *not* a good idea here (more below), but we will try it anyway.\n",
    "1. Compute the mean of the average rating of all films. This is just one number - not a DataFrame.\n",
    "2. Create a contingency table that has larger/smaller than 50% female dialogue on the x-axis and larger/smaller than the mean average rating on the y-axis\n",
    "4. Choose either the binomial test or Fisher's exact test and justify your choice.\n",
    "5. Compute a $p$-value for your test of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreating the \"Who is talking in popular films\" scatter plot\n",
    "# add the average rating\n",
    "\n",
    "# TODO: this is optional but very helpful to understand what we are doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine all 4 boxes in the contingency table\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the test(s)\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV: custom analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem tests such as the one above is that they contain a lot of arbitrary choices and discretizations. Try to think for yourself why this kind of test is not a good idea. \n",
    "\n",
    "However, methods that do not arbitrarily split the data into binary categories are better. For example, we could find the *linear least squares* best fit for a linear function $f(x) = ax+b$ if $x$ is the percentage of female dialogue and $f(x)$ is the IMDB rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T20:27:54.645571Z",
     "iopub.status.busy": "2020-11-28T20:27:54.645324Z",
     "iopub.status.idle": "2020-11-28T20:27:54.809440Z",
     "shell.execute_reply": "2020-11-28T20:27:54.808874Z",
     "shell.execute_reply.started": "2020-11-28T20:27:54.645552Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(df_combined.f_percentage), 2))\n",
    "X[:, 0] = np.ones(len(df_combined.f_percentage))\n",
    "X[:, 1] = np.array(df_combined.f_percentage).flatten()\n",
    "Y = np.array(df_combined.averageRating).flatten()\n",
    "w = np.linalg.solve(X.T @ X, (X.T @ Y))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ax.plot(df_combined.f_percentage, df_combined.averageRating, \".k\", ms=3)\n",
    "ax.plot([0, 1], [w[0], w[0] + w[1]], \"-\", lw=5)\n",
    "\n",
    "plt.ylabel(\"IMDB Rating\", size=20)\n",
    "plt.xlabel(\"Percent Female Dialogue\", size=20)\n",
    "plt.title(\"Percent Female Dialogue vs. IMBD Rating - linear regression\", size=20)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this kind of analysis is dangerous if, instead of plotting rating against the female participation, we plot the rating against the length of the movie, and do the same analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T20:29:25.776340Z",
     "iopub.status.busy": "2020-11-28T20:29:25.776091Z",
     "iopub.status.idle": "2020-11-28T20:29:25.945739Z",
     "shell.execute_reply": "2020-11-28T20:29:25.945157Z",
     "shell.execute_reply.started": "2020-11-28T20:29:25.776320Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(df_combined.words), 2))\n",
    "X[:, 0] = np.ones(len(df_combined.words))\n",
    "X[:, 1] = np.array(df_combined.words).flatten()\n",
    "Y = np.array(df_combined.averageRating).flatten()\n",
    "w = np.linalg.solve(X.T @ X, (X.T @ Y))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ax.plot(df_combined.words, df_combined.averageRating, \".k\", ms=3)\n",
    "ax.plot([0, 7e4], [w[0], w[0] + w[1] * 7e4], \"-\", lw=5)\n",
    "\n",
    "plt.ylabel(\"IMDB Rating\", size=20)\n",
    "plt.xlabel(\"Percent Female Dialogue\", size=20)\n",
    "plt.title(\"length of movie vs. IMBD Rating - linear regression\", size=20)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note that the curve is now affected strongly by just a few data points that are far away"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, think about how you *believe* this data may be causally related. Do people rank movies low because they contain women? Or do unpopular movies have a higher chance of containing many female characters? What is the most striking thing about the plots above: A potential relationship between female participation and rating, or isn't it rather the fact that the there are so few movies with majority female conversation?\n",
    "\n",
    "In situations like this, it can be helpful to treat the data not as a supervised problem (i.e. assume, a priori, a functional relationship between two variables, such as female participation and rating) and instead consider it as an unsupervised problem: What is the joint distribution of movie scores, their length, and gender balance?\n",
    "\n",
    "To do this in a simple fashion, make the following four plots:\n",
    "1. make a scatter plot of the data itself $(X,Y)$\n",
    "2. compute the 2d *joint* histogram of the data. This is an approximation to the joint $p(X,Y)$\n",
    "3. compute histograms for the *marginals* $p(X)$ and $p(Y)$. Plot their outer product $q(X,Y) = p(X) \\cdot p(Y)$. This is an estimate for what the joint *would* be if the two variables *were* independent. \n",
    "4. Do you think $p(X,Y)$ and $q(X,Y)$ differ significantly? To get a sense for strong the difference is, re-draw a random sample from $q(X,Y)$ with equally many points as the \"training\" data. Do you think it looks clearly different? Note that if this distribution does not look significantly different from the raw data, it is not unlikely that the score and female participation are in fact independent of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T20:49:43.724261Z",
     "iopub.status.busy": "2020-11-28T20:49:43.724048Z",
     "iopub.status.idle": "2020-11-28T20:49:44.176184Z",
     "shell.execute_reply": "2020-11-28T20:49:44.175177Z",
     "shell.execute_reply.started": "2020-11-28T20:49:43.724241Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make a plot with four subplots showing task 1-4 from left to right\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part V: What have we learned?\n",
    "\n",
    "The re-sampling analysis indeed seems to suggest a *slight* dependence of the score on the percentage of female speakers. Note that this is only a statement about statistical dependence. The theory of causality (specifically Reichenbach's principle of common cause, which is beyond the scope of the lecture) posits that such a relationship implies a causal *relationship* between the two variables. But not that the relationship is direct, or its direction. In particular, there may be a *confounder*: A hidden cause for both the scores and the gender speech ratio. What might be such a confounder? Come up with at least one hypothesis. Write down your hypothesis. If you want to (optional), try to collect evidence for your hypothesis and present it in the tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write down your hypothesis & investigate it if you want to\n",
    "\n",
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
